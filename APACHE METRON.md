#               **Apache Metron Course** 

[TOC]





# MODULE 1 -  APACHE METRON OVERVIEW

## Apache Metron Framework - Introduction

 Apache Metron is a big data cybersecurity application framework that enables a single view of diverse, streaming security data at scale to aid security operations centers in rapidly detecting and responding to threats.

Apache Metron is a streaming analytics application that makes it faster and easier for security operations personnel to do their job. It is a next generation SOC (security operations center) data analytics and response application that integrates a variety of open source big data technologies into a centralized tool for security monitoring and analysis.

It provides the ability to ingest, process and store diverse data feeds at scale, inclusive of security data feeds, logs, network metadata together, with capabilities for log aggregation, full packet capture indexing, storage, advanced behavioral analytics and data enrichment, while applying the most current threat-intelligence information to security telemetry within a single platform.

## Benefits of using Apache Metron Framework

### SOC Analyst & Investigator Perspective

![](C:\Users\Jelena\AppData\Local\Temp\1529755399832.png)

Below is a brief description of the key steps in a typical analyst/investigator workflow:

#### ·        Looking through Alerts 

o   **Centralized Alerts Console** - Having a centralized dashboard for alerts and the telemetry events associated with the alert across all security data sources in your enterprise is a powerful feature within Metron that prevents the Analyst from jumping from one console to another.

o   **Meta Alerts** - The long term vision of Metron is to provide a suite of analytical models and packs including Alerts Relevancy Engine and Meta-Alerts. Meta Alerts are generated by groupings or analytics models and provide a mechanism to shield the end user from being inundated with 1000s of granular alerts.

o   **Alerts labeled with threat intel data** - Viewing alerts labeled with threat intel from third party feeds allows the analyst to decipher more quickly which alerts are legitimate vs false positives.

#### ·        Collecting Contextual data

o   **Fully enriched messages** - Analyst spend a lot of time manually enriching the raw alerts or events. With Metron, analysts work with the fully enriched message.

o   **Single Pane of Glass UI** - Single pane of glass that not only has all alerts across different security data sources but also the same view that provides the enriched data

o   **Centralized real-time search** - All alerts and telemetry events are indexed in real-time. Hence, the analyst has immediate access to search for all events.

o   **All logs in one place** - All events with the enrichments and labels are stored in a single repository.

#### ·        Investigate

o   **Granular access to PCAP** - After identifying a legitimate threat, more advanced SOC investigators want the ability to download the raw packet data that caused the alert. Metron provides this capability.

o   **Replay old PCAP against new signatures** *-* Metron can be configured to store raw pcap data in Hadoop for a configurable period of time. This corpus of pcap data can then be replayed to test new analytical models and new signatures.

o   Tag Behavior for modeling by data scientists

o   Raw messages used as evidentiary store

o   Asset inventory and User Identity as enrichment sources.

 Note that the above 3 steps in the analyst workflow make up approximately 70% of the time. Metron will drastically decrease the analyst workflow time spend because everything the SOC analyst needs to know is in a single place.

### Metron Benefits - Data Scientist Perspective

![1529755713395](C:\Users\Jelena\AppData\Local\Temp\1529755713395.png)

Below is a brief description of the key steps in a typical data science workflow:

 

·        **Finding the data**

 

o   **All my data is in the same place** - One of the biggest challenges faced by security data scientists is to find the data required to train and evaluate the score models. Metron provides a single repository where the enterprise’s security telemetry data are stored.

o   **Data exposed through a variety of APIs** - The Metron security vault/repository provides different engines to access and work with the data including SQL, scripting languages, in-memory, java, scala, key-value columnar, REST APIs, User Portals, etc.

o   **Standard Access Control Policies** - All data stored in the Metron security vault is secured via [Apache Ranger](http://hortonworks.com/hadoop/ranger/) through access policies at a file system level (HDFS) and at processing engine level (Spark, Hive, HBase, Solr, etc..)

·        **Cleaning the data**

o   **Metron normalizes telemetry events** - As discussed in the first blog where we traced an event being processed by the platform, Metron normalizes all telemetry data into at least a standard 7 tuple json structure allowing data scientists to find and correlate data together more easily.

o   **Partial schema validation on ingest** - Metron framework will validate data on ingest and will filter out bad data automatically which is something that data scientists, traditionally, spend a lot time doing.

·        **Munging Data**

o   **Automatic data enrichment** - Typically data scientists have to manually enrich data to create and test features or have to work with the data/platform team to do so. With Metron, events are enriched in real-time as it comes in and the enriched event is stored in the Metron security vault.

o   **Automatic application of class labels** - Different types of metadata (threat intel information, etc…) is tagged on to the event which allows the data scientists to create feature matrixes for models more easily.

o   **Massively parallel computation framework -** All the cleaning and munging of the data is using distributed technologies that allows the processing of these high velocity/ large volumes to be performant and scalable.

·        **Visualizing Data**

o   **Real-time search + UI** - Metron indexes all events and alerts and provides UI dashboard to perform real-time search.

o   [Apache Zeppelin](http://hortonworks.com/hadoop/zeppelin/) **Dashboards** - Out of the box Zeppelin dashboards will be available that can be used by SOC analysts. With Zeppelin you can share the dashboards, substitute variables, and can quickly change graph types. An example of a dashboard would be to show all HTTP calls that resulted in 404 errors, visualized as a bar graph ordered by the number of failures.

o   **Integration with Jupyter** - Jupyter notebooks will be provided to data scientists for common tasks such as exploration, visualization, plotting, evaluating features, etc.

 Note that the above 4 steps in the data science workflow make up approximately 80% of the time. Metron will drastically reduce the time from hypothesis to model for the data scientist.

## Metron core capabilities

 Apache Metron is a cyber security application framework that provides organizations the ability to ingest, process and store diverse security data feeds at scale in order to detect cyber anomalies and enable organizations to rapidly respond to them.

![1529755884566](C:\Users\Jelena\AppData\Local\Temp\1529755884566.png)

As the diagram above indicates, the Metron framework provides 4 key capabilities:

·         **Security Data Lake / Vault** - Platform provides cost effective way to store enriched telemetry data for long periods of time. This data lake provides the corpus of data required to do feature engineering that powers discovery analytics and provides a mechanism to search and query for operational analytics.

·         **Pluggable Framework** - Platform provides not only a rich set of parsers for common security data sources (pcap, netflow, bro, snort, fireye, sourcefire) but also provides a pluggable framework to add new custom parsers for new data sources, add new enrichment services to provide more contextual info to the raw streaming data, pluggable extensions for threat intel feeds, and the ability to customize the security dashboards.

·         **Security Application** - Metron provides standard SIEM like capabilities (alerting, threat intel framework, agents to ingest data sources) but also has packet replay utilities, evidence store and hunting services commonly used by SOC analysts. 

·         **Threat Intelligence Platform** - Metron will provide next generation defense techniques that consists of using a class of anomaly detection and machine learning algorithms that can be applied in real-time as events are streaming in.

## Metron User Personas

There are six user personas for Metron:

![1529755971678](C:\Users\Jelena\AppData\Local\Temp\1529755971678.png)

## Responsibilities

| **Persona Name**                            | **Description**                                              |
| ------------------------------------------- | ------------------------------------------------------------ |
| **SOC Analyst**                             | ·           Profile: Beginner, Junior-level analyst   ·           Tools Used: SIEM tools/dashboards, Security   endpoint UIs, Email/Ticketing/Workflow Systems   ·           Responsibilities: Monitor security SIEM tools,   search/investigate breaches, malware, review alerts and determine to escalate   as tickets or filter out, follow security playbooks, investigate script   kiddie attacks. |
| **SOC Investigator**                        | ·           Profile: More advanced SME in cybersecurity,   Experienced security analyst, understands more advanced features of security   tools, thorough understanding of networking and platform architecture   (routers, switches, firewalls, security), Ability to dig through and   understand various logs (Network, firewall, proxy, app, etc..)   ·           Tools Used: SIEM/Security tools, Scripting   languages, SQL, command line   ·           Responsibilities: Investigate more   complicated/escalated alerts, investigate breaches, Takes the necessary steps   to remove/quarantine the malware, breach or infected system, hunter for malware   attacks, investigate more complicated attacks like ADT (Advanced Persistent   Threats) |
| **SOC Manager**                             | ·           Profile: Experience managing teams, security   practitioner that has moved into management.   ·           Tools Used: Workflow Systems (e.g: Remedy,   JIRA), Ticket/Alerting Systems   ·           Responsibilities: Assigns Metron Cases to   Analysts. Verifies “completed” metron cases. |
| **Forensic Investigator**                   | ·           Profile: E-discovery experience with security   background.   ·           Tools Used: SIEM and e-discovery tools   ·           Responsibilities: Collect evidence on   breach/attack incident, prepare lawyer’s response to breach, |
| **Security Platform Operations   Engineer** | ·           Profile: Computer Science, developer, and/or   Dev/Ops Background. Experience with Big Data technologies and supported   distributed applications/systems   ·           Tools Used: Security Tools (SIEM, endpoint   solutions, UEBA solutions), provisioning, management and monitoring tooling,   various programming languages, Big Data and distributing computing platforms.   ·           Responsibilities: Helps vet different security   tools before bringing them into the enterprise. Establishes best practices   and reference architecture with respect to provisioning, management and use   of the security tools/ configures the system with respect to   deployment/monitoring/etc. Maintains the probes to collect data, enrichment   services, loading enrichment data, managing threat feeds, etc..Provides care   and feeding of one or more point security solutions. Does capacity planning,   system maintenance and upgrades. |
| **Security Data Scientist**                 | ·           Profile: Computer Science / Math Background,   security domain experience, dig through as much data as available and looks   for patterns and build models   ·           Tools Used: Python (scikit learn, Python   Notebook), R, Rstudio, SAS, Jupyter, Spark (SparkML)   ·           Responsibilities: Work with security data   performing data munging, visualization, plotting, exploration, feature   engineering and generation, trains, evaluates and scores models |

# MODULE 2 - APACHE METRON INSTALLATION

##  VM installation

These instructions are for an Ubuntu host. It uses Metron's Vagrant support to launch a single-node VM installation. The Vagrant image actually uses Debian instead of Ubuntu, because that was readily available, and they are very similar.  Resource requirements: These steps were tested on a Vagrant VM assigned 20 GB RAM, 100GB disk, and 2 CPUs.  Installation may work with lesser resources, but insufficient RAM will require turning off some processes.

 Below is a step-by-step installation guide:

***Step 1. Install pip:*** 

`$ sudo apt-get install python-pip python-dev build-essential`

`$ sudo pip install --upgrade pip`

***Step 2. Install virtual box:*** 

`$ sudo apt-get update (**must do**)`

`$ sudo apt-get install virtualbox`

***Step 3. Install Java:*** 

`$ sudo add-apt-repository ppa:webupd8team/java`

`$ sudo apt update`

`$ sudo apt install oracle-java8-installer`

***Step 4. Install Vagrant:***

·        (latest version of vagrant can see on https://releases.hashicorp.com/vagrant/ , 2.1.1 was the latest version at the time the guide was written)

`$ wget -c <https://releases.hashicorp.com/vagrant/2.1.1/vagrant_2.1.1_x86_64.deb>`

`$ sudo dpkg -i vagrant_2.1.1_x86_64.deb`

***Step 5. Install Maven (with apt-get):*** 

`$ sudo apt-get update`

`$ sudo apt-get install maven`

***Step 6. Install Ansible:***

- Only      version 2.0.0.2 is supported by metron (as per the documents available      online)
- Execute the following commands to install ansible:

`$ sudo apt-get update`

`$ sudo apt-get install software-properties-common`

`$ sudo apt-add-repository ppa:ansible/ansible`

`$ sudo apt-get update`

`$ sudo apt-get install ansible`

***Step 7. Set Java and Maven Paths:***  

- mvn -v      in terminal should show the maven path
- Edit /etc/environments
- Add:      JAVA_HOME="java path"
- Add:      MAVEN_HOME="maven path"

***Step 8. Clone project from Apache Metron (incubating) repo:*** 

- <https://github.com/apache/metron>

***Step 9. Now build the packages and launch the Vagrant VM:*** 

`$ cd incubator-metron (for example cd /Downloads/metron-master)`

`$ mvn clean package -DskipTests`

`$ vagrant plugin install vagrant-hostmanager`

`$ cd metron-deployment/vagrant/(select the module you want to run)`

`$ vagrant up`

- If  things fail, then run: vagrant provision (multiple times)

***Step 10. If launch is successful:*** 

- The      Vagrant VM will be running as "node1"

- Ambari      should be available in your browser at http://node1:8080/

- Kibana      should be available in your browser at http://node1:5000/

- Monit      should be available in your browser at http://node1:2812/ 

- - If  Monit fails to work, or does not provide the expected data, then do the following:

  - vagrant       ssh

  - sudo vi (or nano or vim) /etc/hosts

  - There should be a line near the top of the file that reads:

  - - 127.0.0.1  localhost
    - (this is good)

  - However, sometimes Vagrant hostmanager adds a line that says:

  - - 127.0.0.1         node1  node1
    - (this is bad)

  - If  both lines exist, remove the bad line.  If the good line does not exist, replace the bad line with the good line.

  - Save and exit the editor

  - The rest should work fine

## Docker / Vagrant installation

In this guide, we will show the installation Docker CE on Ubuntu. First of all, we will state the prerequisites for installation. After that, the installation process will be displayed and this process can be done on three different ways, depending on your needs:

- Most users set up Docker’s repositories and install from them, for ease of installation and upgrade tasks. This is the recommended approach.
- Some      users download the DEB package and install it manually and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.
- In testing and development environments, some users choose to use automated convenience scripts to install Docker.

#### Prerequisites for Docker CE installation

Prerequisites for installing the Docker are:

- **OS requirements:**  To install Docker CE, you need the 64-bit      version of one of these Ubuntu versions:

- - Bionic       18.04 (Docker CE 18.05 Edge and higher only)
  - Artful       17.10
  - Xenial       16.04 (LTS)
  - Trusty       14.04 (LTS)

- **Supported storage drivers:**  Docker CE on Ubuntu supports overlay2 and  aufs storage drivers:

- - For new installations on version 4 and higher of the Linux  kernel, overlay2 is supported and preferred over aufs.
  - For version 3 of the Linux kernel, aufs is supported because overlay or overlay2 drivers are not supported by that kernel version.Xenial 16.04 (LTS).
  - If  you need to use aufs, you need to do additional preparation:

- For Xenial 16.04 and newer see:  <https://docs.docker.com/storage/storagedriver/aufs-driver/>                                        

- For Trusty 14.04 execute the following commands:

  `$ sudo apt-get update`

  `$ sudo apt-get install \`

  ​    `linux-image-extra-$(uname -r) \`

  After checking the fulfillment of the prerequisites, it may be started with the installation.

  

#### Install Docker CE using the repository

Before you install Docker CE for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository. The repositoy can be set through the following steps:

***Step 1. Update the apt package index:*** 

`$ sudo apt-get update`

***Step 2. Install packages to allow apt to use a repository over HTTPS:***

`$ sudo apt-get install \`

​    `apt-transport-https \`

​    `ca-certificates \`

​    `curl \`

***Step 3. Add Docker’s official GPG key*** :

`$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -` 

Verify that you now have the key with the fingerprint 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88, by searching for the last 8 characters of the fingerprint. 

`$ sudo apt-key fingerprint 0EBFCD88`

 `pub   4096R/0EBFCD88 2017-02-22`

​      `Key fingerprint = 9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88`

`uid                  Docker Release (CE deb) <docker@docker.com>`

`sub   4096R/F273FCD8 2017-02-22`

***Step 4. Use the following command to set up the stable repository:*** 

`$ sudo add-apt-repository \`

   `"deb [arch=amd64] https://download.docker.com/linux/ubuntu \`

   `$(lsb_release -cs) \`

   `stable"`

After the repostory is set it is necessary to go through the following steps to install Docker CE: 

***Step 1. Update the apt package index:*** 

`$ sudo apt-get update`

***Step 2. Install the latest version of Docker CE, or go to the next step to install a specific version:*** 

`$ sudo apt-get install docker-ce` 

***Step 3. To install a specific version of Docker CE, list the available versions in the repo, then select and install:*** 

- List the versions available in your repo:

`$ apt-cache madison docker-ce`

`docker-ce | 18.03.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu` 

- Install a specific version by its fully qualified package name, which is package name (docker-ce) “=” version string (2nd column), for example, docker-ce=18.03.0~ce-0~ubuntu : 

`$ sudo apt-get install docker-ce=<VERSION>` 

The Docker daemon starts automatically. 

***Step 4. Verify that Docker CE is installed correctly by running the hello-world image:*** 

`$ sudo docker run hello-world` 

This command downloads a test image and runs it in a container. When the container runs, it prints an informational message and exits.

 Docker CE is installed and running. The docker group is created but no users are added to it. You need to use sudo to run Docker commands. Continue to linux postinstall (https://docs.docker.com/install/linux/linux-postinstall/) to allow non-privileged users to run Docker commands and for other optional configuration steps.

#### Install Docker CE from a package 

If you cannot use Docker’s repository to install Docker CE, you can download the .deb file for your release and install it manually. You need to download a new file each time you want to upgrade Docker CE. You can do this by following steps: 

**Step 1. Go to** [**https://download.docker.com/linux/ubuntu/dists/**](https://download.docker.com/linux/ubuntu/dists/)**, choose your Ubuntu version, browse to pool/stable/ and choose amd64, armhf, ppc64el, or s390x. Download the .deb file for the Docker version you want to install.**

***Step 2. Install Docker CE, changing the path below to the path where you downloaded the Docker package:*** 

`$ sudo dpkg -i /path/to/package.deb` 

The Docker daemon starts automatically. 

***Step 3. Verify that Docker CE is installed correctly by running the hello-world image:*** 

`$ sudo dpkg -i /path/to/package.deb` 

This command downloads a test image and runs it in a container. When the container runs, it prints an informational message and exits.

 Docker CE is installed and running. The docker group is created but no users are added to it. You need to use sudo to run Docker commands. Continue to linux postinstall (https://docs.docker.com/install/linux/linux-postinstall/) to allow non-privileged users to run Docker commands and for other optional configuration steps.

#### Install Docker CE using the convenience script 

Docker provides convenience scripts at [get.docker.com](https://get.docker.com/) and [test.docker.com](https://test.docker.com/) for installing edge and testing versions of Docker CE into development environments quickly and non-interactively. The source code for the scripts is in the [docker-install repository](https://github.com/docker/docker-install). **Using these scripts is not recommended for production environments**, and you should understand the potential risks before you use them:

- The      scripts require root or sudo privileges to run.      Therefore, you should carefully examine and audit the scripts before      running them.
- The      scripts attempt to detect your Linux distribution and version and      configure your package management system for you. In addition, the scripts      do not allow you to customize any installation parameters. This may lead      to an unsupported configuration, either from Docker’s point of view or      from your own organization’s guidelines and standards.
- The      scripts install all dependencies and recommendations of the package      manager without asking for confirmation. This may install a large number      of packages, depending on the current configuration of your host machine.
- The      script does not provide options to specify which version of Docker to      install, and installs the latest version that is released in the “edge”      channel.
- Do not      use the convenience script if Docker has already been installed on the      host machine using another mechanism.

This example uses the script at [get.docker.com](https://get.docker.com/) to install the latest release of Docker CE on Linux. To install the latest testing version, use [test.docker.com](https://test.docker.com/) instead. In each of the commands below, replace each occurrence of get with test.

#### Deploy Metron 

The computer used to deploy Apache Metron will need the following components installed.

- **Ansible (2.0.0.2 or 2.2.2.0)**
- **Docker**
- **Vagrant 1.8.1+**
- **Vagrant Hostmanager Plugin** 
- **Virtualbox  5.0.16+**
- **Python 2.7.11+**
- **Maven 3.3.9+**

Since the installation of these components has been displayed in chapter 2.1, the focus will be on the deploying Metron. To deploy metron you have to go through the following steps: 

***Step 1. Ensure that the Docker service is running:*** 

`$ sudo systemctl status docker `

The output should be similar to the following, showing that the service is active and running: 

Output

● docker.service - Docker Application Container Engine

   Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)

   Active: active (running) since Sun 2016-05-01 06:53:52 CDT; 1 weeks 3 days ago

​     Docs: https://docs.docker.com

 Main PID: 749 (docker)

***Step 2. Deploy Metron*** 

`$ cd metron-deployment/vagrant/quick-dev-platform`

`$ vagrant up`

Should the process fail before completing the deployment, the following command will continue the deployment process without re-instantiating the host. 

`$ vagrant provision` 

#### Cloud installation (Amazon EC2)

This project fully automates the provisioning of Apache Metron on Amazon EC2 infrastructure. Starting with only your Amazon EC2 credentials, this project will create a fully-functioning, end-to-end, multi-node cluster running Apache Metron.

Warning: Amazon will charge for the use of their resources when running Apache Metron. The amount will vary based on the number and size of hosts, along with current Amazon pricing structure. Be sure to stop or terminate all of the hosts instantiated by Apache Metron when not in use to avoid unnecessary charges.

The Ansible playbook uses the following defaults for AWS deployment:

- **Instances**: 10
- **Region: us-west-2**
- **Instance type: m4.xlarge**

As for the prerequisites, the host used to deploy Apache Metron will need the following software tools installed. The following versions are known to work as of the time of this writing, but by no means are these the only working versions:

- **Ansible 2.0.0.2, 2.2.2.0, or 2.5.0**
- **Python 2.7.11**
- **Maven 3.3.9**

Any platform that supports these tools is suitable, but the following instructions cover only macOS. The easiest means of installing these tools on a Mac is to use the excellent Homebrew project.

***Step 1. Install Homebrew*** 

- (Refer to the Homebrew home page (<https://brew.sh/>) for the latest installation instructions.) .

`/usr/bin/ruby -e "$(curl -fsSL` 

`https://raw.githubusercontent.com/Homebrew/install/master/install)"`

***Step 2. Install all of the required tools and dependencies*** :

`brew update`

`brew tap caskroom/versions`

`brew cask install java8 vagrant virtualbox`

***Step 3. Install Ansible by following the instructions from link:*** 

<https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html#latest-releases-via-pip> 

`$ cat ~/.ssh/id_rsa.pub`

`ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQChv5GJxPjR39UJV7VY17ivbLVlxFrH7UHwh1Jsjem4d1eYiAtde5N2y65/HRNxWbhYli9ED8k0/MRP92ejewucEbrPNq5mytPqdC4IvZ98Ln2GbqTDwvlP3T7xa/wYFOpFsOmXXql8216wSrnrS4f3XK7ze34S6/VmY+lsBYnr3dzyj8sG/mexpJgFS/w83mWJV0e/ryf4Hd7P6DZ5fO+nmTXfKNK22ga4ctcnbZ+toYcPL+ODCh8598XCKVo97XjwF5OxN3vl1p1HHguo3cHB4H1OIaqX5mUt59gFIZcAXUME89PO6NUiZDd3RTstpf125nQVkQAHu2fvW96/f037 nick@localhost`

- If  this file does not exist, run the following command at a terminal and accept all defaults. Only the public key, not the private key, will be uploaded to Amazon and configured on each host to enable SSH connectivity. While it is possible to create and use an alternative key those details will not be covered.

`ssh-keygen -t rsa` 

***Step 5. Ensure the JAVA_HOME environment variable is set*** 

`export` 

`JAVA_HOME="/Library/Java/JavaVirtualMachines/jdk1.8.0_162.jdk/Contents/Home"` 

- Notice:  You must replace the path with the installed JDK version path

If you already have an Amazon Web Services account that you have used to deploy EC2 hosts, then you should be able to skip the next few steps.

1. Head over to [Amazon Web Services](http://aws.amazon.com/) and      create an account. As part of the account creation process you will need      to provide a credit card to cover any charges that may apply.
2. Create a set of user      credentials through [Amazon's Identity and Access Management (IAM) ](https://console.aws.amazon.com/iam/)dashboard.      On the IAM dashboard menu click "Users" and then "Create      New User". Provide a name and ensure that "Generate an access      key for each user" remains checked. Download the credentials and keep      them for later use.
3. While still in [Amazon's      Identity and Access Management (IAM) ](https://console.aws.amazon.com/iam/)dashboard, click on      the user that was previously created. Click the "Permissions"      tab and then the "Attach Policy" button. Attach the following      policies to the user.

- AmazonEC2FullAccess
- AmazonVPCFullAccess

1. Apache Metron uses      the [official, open source CentOS 6](https://aws.amazon.com/marketplace/pp/B00NQAYLWO) Amazon      Machine Image (AMI). If you have never used this AMI before then you will      need to accept Amazon's terms and conditions. Navigate to the [web page for this AMI](https://aws.amazon.com/marketplace/pp/B00NQAYLWO) and click the      "Continue" button. Choose the "Manual Launch" tab then      click the "Accept Software Terms" button.

Having successfully created your Amazon Web Services account, hopefully you will find that the most difficult tasks are behind us. After that you can deploy Metron and you have to go through the following steps:

 ***Step 1. Use the Amazon access key by exporting its values via the shell's environment. This allows Ansible to authenticate with Amazon EC2. For example:*** 

`export AWS_ACCESS_KEY_ID="AKIAI6NRFEO27E5FFELQ"`

`export AWS_SECRET_ACCESS_KEY="vTDydWJQnAer7OWauUS150i+9Np7hfCXrrVVP6ed"`

- Notice: You must replace the access key values above with values from your own access key.

***Step 2. Start the Apache Metron deployment process. When prompted provide a unique name for your Metron environment or accept the default.*** 

`$ ./run.sh`

`Metron Environment [metron-test]: my-metron-env`

- The process is likely to take between 70-90 minutes. Fortunately, everything is fully automated and      you should feel free to grab a coffee.

After the deployment has completed successfully, a message like the following will be displayed. Navigate to the specified resources to explore your newly minted Apache Metron environment. 

`TASK [debug] *******************************************************************`

`ok: [localhost] => {`

​    `"Success": [`

​        `"Apache Metron deployed successfully",`

​        `"   Metron  @  http://ec2-52-37-255-142.us-west-2.compute.amazonaws.com:5000",`

​        `"   Ambari  @  http://ec2-52-37-225-202.us-west-2.compute.amazonaws.com:8080",`

​        `"   Sensors @  ec2-52-37-225-202.us-west-2.compute.amazonaws.com on tap0",`

​        `"For additional information, see https://metron.apache.org/'"`

​    `]`

`}`

Each of the provisioned hosts will be accessible from the internet. Connecting to one over SSH as the user centos will not require a password as it will authenticate with the pre-defined SSH key. 

`ssh centos@ec2-52-91-215-174.compute-1.amazonaws.com` 

# MODULE - 3 METRON ARCHITECTURE

- Metron components
  - Metron Modules
  - Domain Specific Languages

- Logical architecture

  - Step 1 - Telemetry Event Buffer

  - Step 2 - Process (Parse, Normalize, Validate and Tag)

  - Step 3 - Encich

  - Step 4 - Label

  - Step 5 - Alert and Persist

  - Step 6 - UI Portal and Data & Integration Services

  - Step 7a - Fast Telemetry Ingest

  - Step 7b - Telemetry Ingest

    

![1529761365932](C:\Users\Jelena\AppData\Local\Temp\1529761365932.png)

## Logical architecture 

#### Step 1 - Telemetry Event Buffer

All raw events from each telemetry security data source captured by Apache Nifi or custom Metron probe will be pushed into its own Kafka topic. The arrival of a telemetry event into the ingest buffer marks the start of where the Metron processing begins.

#### Step 2 - Process (Parse, Normalize, Validate and Tag)

Each raw event will be parsed and normalized into a standardized flat JSON structure. Every event will be standardized into at least a 7-tuple JSON structure. This is done so the topology correlation engine further downstream can correlate messages from different topologies by these fields. The standard field names are as follows:

*ip_src_addr: layer 3 source IP*

*ip_dst_addr: layer 3 dest IP*

*ip_src_port: layer 4 source port*

*ip_dst_port: layer 4 dest port*

*protocol: layer 4 protocol*

*timestamp (epoch)*

*original_string: A human friendly string representation of the message*

At this step, one can also validate the raw event and tag it with additional metadata which will be used by downstream processing.

After Step 3, the raw Bro event will look like the following:

![1529761427712](C:\Users\Jelena\AppData\Local\Temp\1529761427712.png)

#### Step 3 - Enrich

Once the raw security telemetry event has been parsed and normalized, the next step is to enrich different data elements of the normalized event. Examples of enrichment are GEO where an external IP address is enriched with GeoIP information (lat/long coordinates + City/State/Country) or HOST enrichment where an IP gets enriched with Host details (e.g: IP corresponds to Host X which is part of a web server farm for an e-commerce application).

After Step 4, the enriched Bro event will look something like the following:

![1529761452078](C:\Users\Jelena\AppData\Local\Temp\1529761452078.png)

#### Step 4 – Label

After enrichment, the telemetry event goes through the labeling process. Actions done within this phase include threat intel cross reference checks where elements within the telemetry event can be used to do look ups against threat intel feed data sources like [Soltra](https://soltra.com/) produced Stix/Taxii feeds or other threat intel aggregator services. These threat intel services will then “label” the telemetry event with threat intel metadata when a hit occurs.

Other types of services include executing/scoring analytical models using model as a service pattern with the telemetry events that are flowing in (more details on Analytical Models/Packs and Model as Service patterns will be coming in upcoming blogs of this series).

After step 5 assuming the bro telemetry event had a threat intel hit, the message would look something like the following:

![1529761473706](C:\Users\Jelena\AppData\Local\Temp\1529761473706.png)

#### Step 5 - Alert and Persist

During this phase, certain telemetry events can initiate alerts. These types of telemetry events are then indexed in an alert index store. A telemetry event can spawn an alert triggered by a number of factors including:

The event type - The raw telemetry event itself is an alert. For example, any event generated by [Snort](https://www.snort.org/) is an alert so it will automatically be indexed as an alert.

Threat intel hit - If raw telemetry event has a threat intel hit, it will be marked as an alert.

Also during this step, all enriched and labeled telemetry events are indexed and persisted in Hadoop for long term storage. The storage of these events in Hadoop produces a security data vault within the enterprise that enables next generation analytics to be performed.

After step 6, the telemetry event is stored in HDFS and indexed in Elastic/Solr based on configuration. The persisted event in HDFS looks something like the following:

![1529761496409](C:\Users\Jelena\AppData\Local\Temp\1529761496409.png)

#### Step 6 - UI Portal and Data & Integration Services

Steps 1 through 6 provide the mechanism to ingest, parse, normalize, enrich, label, index and store all security telemetry data across a diverse set of data sources in your enterprise into a single security data vault. This allows the Metron platform to provide a set of services for different types of security users to perform their jobs more effectively. Some of these services include:

Real-time Search and Interactive Dashboards / Portals - Single Pane of glass for security operation analysts to view alerts and correlate alerts to the granular telemetry events that caused the alert.

Data Modeling / Feature Engineering Services - Since the Metron framework normalizes and enriches the data and stores it into the security data lake (HDFS, Hbase) in standardized locations, then various analytical models can be provided by the platform. 

These models will have specifications for the feature matrix required, and hence, the process of feature engineering which is the most complex aspect of analytics becomes considerably simplified. Data Modeling services required for the feature matrix will be provided by tools such as Jupyter, IPython and Zeppelin.

Integration and Extensibility Layers - One of the most powerful features of the Metron platform is the ability to customize it for your own needs/requirements which includes:

- Ingesting new data sources
- Adding new parsers
- Adding new enrichment services
-  Adding new Threat Intel feeds
-  Building, deploying and executing new analytical models
- Integration with enterprise workflow engines
- Customizing the Security Dashboards and portals.

#### Step 7a - Fast Telemetry Ingest

For high volume network telemetry data like packet capture (PCAP), Netflow/YAF, and Bro/DPI, custom Metron probes will be available to ingest data directly from a network tap.

An example would be capturing Bro data using the custom C++ Metron probe. The raw Bro event captured by the Bro probe would look something like the following:

![1529761599072](C:\Users\Jelena\AppData\Local\Temp\1529761599072.png)

#### Step 7b - Telemetry Ingest

For most security telemetry data sources that uses transports and protocols like file, syslog, REST, HTTP, custom API, etc., Metron will use Apache Nifi to ingest data at the source.

![1529761618018](C:\Users\Jelena\AppData\Local\Temp\1529761618018.png)

## Metron components

- Metron Modules
- Domain Specific Languages

## Metron Modules

 

| **MODULE NAME**                          | **MODULE DESCRIPTION**                                       | **CURRENT VERSION** |
| ---------------------------------------- | ------------------------------------------------------------ | ------------------- |
| metron-platform - metron-pcap            | Topology for   streaming network packets into HDFS for use with the PCAP Service | 0.1BETA             |
| metron-platform - metron-api             | Service for running   analytics/filtering on the PCAP files in HDFS put there by the PCAP Topology | 0.1BETA             |
| metron-sensors                           | Sensors feeding   Metron dashboards and analytics            | 0.1BETA             |
| metron-platform - metron-data-management | Loaders for bulk   loading enrichment and threat intelligence stores | 0.1BETA             |
| metron-ui                                | Metron SOC Analyst UI                                        | 0.1BETA             |
| metron-deployment                        | Scripts for   automating Metron deployments                  | 0.1BETA             |

### Streaming

Metron Streaming is a module that deals with stream processing including telemetry ingest, enrichment, threat intelligence referencing, alerting, and real-time scoring of machine learning models.  Metron Streaming is built on top of ApacheStorm, which is a massively scalable stream processing engine with unique properties that make it a good fit for processing networking and logging data.  Telemetry generated by various sensors is processed by Metron's Storm topologies.  There are three topology types.  

| **Topology name**                | **Description**                                              |
| -------------------------------- | ------------------------------------------------------------ |
| Parsing/Normalizing Topology     | Receives a telemetry   message in it's native format and normalizes it to a common Metron JSON   format. There is one topology per source and the output is piped to the   Enrichment/Threat Intel topology |
| Enrichment/Threat Intel Topology | Takes an normalized   Metron JSON, enriches it, cross-references it against threat intelligence,   tags it with alerts (where appropriate), runs the result against the scoring   component of machine learning models (where appropriate) and stores the   telemetry in a data store supported by Metron |
| PCAP Topology                    | The PCAP topology is designed to   process telemetry produced by [Metron's   PCAP Probe](https://cwiki.apache.org/confluence/display/METRON/Metron+Packet+Capture+Probe+Design) and it's   output is designed to be visualized by [Metron's   PCAP Service](https://cwiki.apache.org/confluence/display/METRON/PCAP+Service). |

#### Parsing Topology

Metron Parsing Topology (also known as the Normalizing Topology) is designed to take a sensor input (in it's native format) and turn it into a [Metron JSON Object](https://cwiki.apache.org/confluence/display/METRON/Metron+JSON+Object).  The topology consists of two components: a standard [Storm Kafka Spout](http://storm.apache.org/documentation/storm-kafka.html) (reads data from a Kafka topics and ingests it into a storm topology) and a Metron Parser Kafka Bolt (which parses the message and puts it back onto a Kafka "enrichment" topic. 

The Kafka Parser Bolt is an extensible bolt that can take two types of parsers: GROK and purpose-built Java.  It is our strong preference to build up as much coverage as we can using the Grok parsers, as they require no coding.  However, the drawback of the Grok parsers is that they are much slower than Java parsers and sometimes the telemetry is so complex that writing a Grok statement for it is not feasible.  See our list of [supported devices ](https://cwiki.apache.org/confluence/display/METRON/What's+Currently+Supported)for which parser type supports a particular device.

| **PARSER TYPE** | **TELEMETRY TYPE**            |
| --------------- | ----------------------------- |
| Grok            | Simple to parse, low volume   |
| Java            | Complex to parse, high volume |

Each parser outputs a Metron JSON formatted message.  The reason why JSON was chosen as a format for Metron is a very flexible data structure that allows nesting and lists.  We do not dictate what the JSON structure should look like, however, Metron is looking for specific normalized fields in order to do downstream processing.  

##### Grok Parsesr

A parser takes an input, which is usually a byte array coming from the Kafka Spout, and turns it into a  JSON Object.  The Grok parser does this by utilizing the Grok library  inside of the Parser Kafka Bolt Adapter.  So instead of coding the parser in Java, the Grok Adapter allows for creating Grok Statements, outputs of which is understood by the Storm Bolt, which turns it into a JSON.

##### Java Parsers

Most parsers for Metron should be written as Grok parsers except when the telemetry is either very high velocity or very complex so it's not possible to write a Grok statement for it.  All metron Java parsers should extend the Metron Parser Base and output a Metron JSON Object.

##### Metron JSON Object 

Numerous sensors log in different formats.  The parser should normalize at least the following subset of fields to the following Metron JSON naming conventions:

| **DESCRIPTION**                               | **FIELD NAME** | **FIELD VALUE**                                              |
| --------------------------------------------- | -------------- | ------------------------------------------------------------ |
| Any field containing a source IP address      | Ip_src_addr    | Octets (xxx.xxx.xxx.xxx)                                     |
| Any field containing a destination IP address | Ip_dst_addr    | Octets (xxx.xxx.xxx.xxx)                                     |
| Any field containing a source port            | Ip_src_port    | Integer                                                      |
| Any field containing a destination port       | Ip_dst_port    | Integer                                                      |
| Any field containing a protocol               | protocol       | String as a protocol, all caps.   So if protocol = 6, value should be TCP |
| Timestamp                                     | timestamp      | Epoch timestamp   (timestamp comes from sensor, not parser)  |
| Message Type                                  | source.type    | yaf\|snort\|bro\|etc...                                      |
| Timestamp                                     | start_time     | Epoch timestamp                                              |
| Timestamp                                     | End_time       | Epoch timestamp                                              |

####  Enrichment/Threat Intel Topology

The input to this topology is the [normalized Metron JSON](https://cwiki.apache.org/confluence/display/METRON/Metron+JSON+Object) produced by the [Parser/Normalizing Topology](https://cwiki.apache.org/confluence/display/METRON/Parsing+Topology).  The output of this topology is written to a number of [data stores supported by Metron](https://cwiki.apache.org/confluence/display/METRON/Supported+Data+Stores).  There are two streams: a message stream and an enrichment stream(s).  The message stream carries the original message, while the enrichment stream tack on additional enrichments or pieces of threat intelligence to the message. 

 

| **BOLT NAME**              | **FUNCTIONALITY**                                            |
| -------------------------- | ------------------------------------------------------------ |
| Enrichment Splitter        | This bolt extracts   fields and values from a message that can be enriched and sends them to the   appropriate enrichment bolt. The configuration for which fields have an   associated enrichment is stored in Zookeper. |
| Enrichment Bolt            | This bolt takes the   enrichment information from the splitter bolt (key + value), extracts the   value, cross references the value against the enrichment store, and then   sends the value of the enrichment to the joiner bolt. There can be n   enrichment bolts and each enrichment bolt has to be associated with a back   end store (which is primarily Hbase). These bolts also use an in-memory cache   so they don't thrash the back end reference store. There is a corresponding   bulk loader provided per enrichment to be able to bootstrap the enrichment   store |
| Enrichment Joiner Bolt     | Join the enrichments   with the original message. The bolt waits for all the enrichments to come in   prior to joining. If an enrichment part does not come in, then the bolt times   out that enrichment and sends the message down the topology without that   enrichment part. |
| Threat Intel Splitter Bolt | Splits the message the   same way the Enrichment Splitter does. Based on Zookeeper configs, parts of   the message that can be enriched get passed to the Threat Intel bolt, which   checks for threat data on that element. |
| Threat Intel Bolt          | This bolt takes the   enrichment information from the splitter bolt (key + value), extracts the   value, cross references the value against the Threat Intel store, and then   sends the value of the enrichment to the joiner bolt. There can be n   enrichment bolts and each enrichment bolt has to be associated with a back   end store (which is primarily Hbase). These bolts also use an in-memory cache   so they don't thrash the back end reference store. There is a corresponding   bulk loader provided per enrichment to be able to bootstrap the enrichment   store |
| Threat Intel Joiner Bolt   | Join the enrichments   with the original message. The bolt waits for all the enrichments to come in   prior to joining. If an enrichment part does not come in, then the bolt times   out that enrichment and sends the message down the topology without that   enrichment part. If there is threat intel for the message the bolt will add   an element alert=true |
| Writer Bolt                | Extensible writer bolt   to write Metron's (enriched) telemetry to a data store. See the references   descriptions for the number of sources supported by Metron. More than one   writer can be run in a topology, allowing multiple data stores to be   populated with Metron data |

#####  Enrichments

Enrichments add additional context to the streaming message.  For example, if a given message has an external IP an enrichment would be to tag geo data to that message.  Another example would be if a message contains a domain name then we can tag a whois entry to that message.  There are three primary benefits to adding context via enrichments to a message:

- Correlation: if you know which user and asset the message is intended to and where it's coming from it's easier to correlated it with other related messages 

- ML: having full context via streaming allows scoring against ML models via real time as opposed to gathering the context in batch and then applying the model in batch 

- Accuracy: the underlying enrichment information always changes (users sign on and off, machines change IPs, etc) and you want to enrich as close to the capture time as possible

- Investigation: having a full context for a given piece of metadata or alert means less consoles to fumble through and gets us closer to the 'single pane of glass' interface 

Metron currently provides an extensible framework to plug in enrichments.  Each enrichment has two components: an enrichment data source and and enrichment bolt.

![1529762228642](C:\Users\Jelena\AppData\Local\Temp\1529762228642.png)

Prior to enabling an enrichment capability within Metron the enrichment store (which for Metron is primarily Hbase) has to be loaded with enrichment data.  Enrichment data can either be bulk loaded from HDFS or be streamed into enrichment store via pluggable loading framework.  The enrichment loader transforms the enrichment into a JSON format that is understandable to Metron.  The loading framework has additional capabilities for aging data out of the enrichment stores based on time.  Once the stores are loaded an enrichment bolt that can interact with the enrichment store can be incorporated into the enrichment topology.  Each enrichment bolt can enrich a specific field/tag within a Metron message.  When a bolt recognizes that it is able to enrich a field it reaches into the enrichment store, pulls out the enrichment, and tags the message with the enrichment.  The enrichment is then stored within the bolt's in-memory cache.  Metron uses the underlying Storm routing capabilities to make sure that similar enrichment values are sent to the appropriate bolts that already have these values cached in-memory, thereby giving Metron it's superior scale and speed when compared to other big data streaming systems that do not have this capability.

The following list of enrichments is Currently supported in Metron: 

![1529762275341](C:\Users\Jelena\AppData\Local\Temp\1529762275341.png)

##### Threat Intel

Metron currently provides an extensible framework to plug in threat intel sources.  Each threat intel source has two components: an enrichment data source and an enrichment bolt.  The threat intelligence feeds are bulk loaded and streamed into a threat intelligence store similarly to how the enrichment feeds are loaded.  The keys are loaded in a key-value format.   The key is the indicator and the value is the JSON formatted description of what the indicator is.  It is recommended to use a threat feed aggregator such as Soltra to dedup and normalize the feeds via Stix/Taxii.  Metron provides an adapter that is able to read Soltra-produced Stix/Taxii feeds and stream them into HBase, which is the data store of choice to back high-speed threat intel lookups of Metron.  Metron additionally provides a flat file and Stix bulk loader that can normalize, dedup, and bulk load or stream threat intel data into HBase even without the use of a threat feed aggregator.  

![1529762321335](C:\Users\Jelena\AppData\Local\Temp\1529762321335.png)

The following threat intel feeds and formats are supported by Metron's threat intel loader framework:  

| **Threat Feed** | **Feed Indicators** | **Feed Format** | **Feed Description**           | **Feed Link**            | **Refresh Rate**     |
| --------------- | ------------------- | --------------- | ------------------------------ | ------------------------ | -------------------- |
| Soltra          | Multiple            | Stix/Taxii      | Threat Intel Feed   Aggregator | <https://soltra.com/>    | Poll every 5 minutes |
| Hail A Taxi     | Multiple            | Stix/Taxii      | External Stix/Taxii Feed       | <http://hailataxii.com/> | Poll every 5 minutes |
|                 | …More to come       |                 |                                |                          |                      |

####  PCAPP Topology

 The PCAP Topology is designed to take network packets off of the PCAP Kafka topic and store them in HDFS as Sequence files.  It has a single bolt that functions as a Kafka Spout, and HDFS Writer, where it stores the packets into HDFS.  The PCAP Topology has a hard dependency on the [PCAP Probe](https://cwiki.apache.org/confluence/display/METRON/Metron+Packet+Capture+Probe+Design). 

![1529762481288](C:\Users\Jelena\AppData\Local\Temp\1529762481288.png)

### PCAP Service

A prerequisite to having the PCAP service is having the [PCAP Topology](https://cwiki.apache.org/confluence/display/METRON/PCAP+Topology) up and running. 

![1529762638695](C:\Users\Jelena\AppData\Local\Temp\1529762638695.png)



The service consists of a Kibana PCAP Panel that is backed by a restful API.  A Sample screenshot of the Kibana/Banana PCAP panel is provided below. 

![1529762502831](C:\Users\Jelena\AppData\Local\Temp\1529762502831.png)

The PCAP Kibana/Banana Panel takes the following variables:

| **Variable**    | **Description**      | **Format**      | **Required** |
| --------------- | -------------------- | --------------- | ------------ |
| ip_src_addr     | Source ip            | xxx.xxx.xxx.xxx | YES          |
| **ip_dst_addr** | Dest ip              | xxx.xxx.xxx.xxx | YES          |
| ip_src_port     | Source port          | int             | NO           |
| ip_dst_port     | Dest port            | int             | NO           |
| protocol        | Protocol (as String) | String          | NO           |
| timeframe       | Time –x minutes      | epoch           | YES          |

### Sensors

Metron supports the following list of Sensors and formats: 

![1529762720313](C:\Users\Jelena\AppData\Local\Temp\1529762720313.png)

#### Metron Bro Capture Design

![1529762796137](C:\Users\Jelena\AppData\Local\Temp\1529762796137.png)

Bro is primarily used as a Deep Packet Inspection (DPI) metadata generator.  Metron does not currently utilize the IDS alerts features of Bro.  Metron integrates with Bro via a Bro Plug-in, and does not require recompiling of Bro code.  The instructions for building and installing the Bro plug-in with Bro can be found here: <https://github.com/apache/incubator-metron/blob/master/bro-plugin-kafka/README.md> .  The Bro plug-in formats Bro output messages into JSON and puts them onto a Kafka topic.  The JSON messages outputted by the Bro plug-in are designed to be parsed by the Metron Bro parsing topology.

DPI Metadata is not a replacement for PCAP, but rather a compliment.  Extracting DPI Metadata (layer 7 visibility) is expensive, and thus, is performed only on selected protocols.  We recommend enabling DPI for HTTP and DNS protocols.  Hence, while the PCAP probe records every single packets it sees on the wire, the DPI metadata is extracted only for a subset of these packets.

It should also be noted that while Metron ships with a Bro DPI sensor via a plug-in, Bro is not the only tool for extracting DPI.  [Qosmos](http://www.qosmos.com/) is another popular tool for doing DPI and we plan on supporting it soon. 

#### Metron Packet Capture Probe Design

![1529762910170](C:\Users\Jelena\AppData\Local\Temp\1529762910170.png)

The network packet capture probe is designed to capture raw network packets off the wire and bulk load them into Kafka.  Kafka files are then picked up by the PCAP Storm Topology and bulk loaded into HDFS.  Each file is stored in HDFS as a Sequence file.  Once in HDFS, the PCAP service is used to read and the Sequence files and deliver compliant PCAP files via a restful API. There can be multiple probes pushing into the same Kafka topic.  The recommended hardware for the probe is an [Intel family of network adapters](http://www.intel.com/content/www/us/en/ethernet-products/converged-network-adapters/ethernet-x520.html) that are supportable by DPDK.   

#### Metron Yaf Capture Design

![1529762956107](C:\Users\Jelena\AppData\Local\Temp\1529762956107.png)

Not everyone wants to ingest PCAP due to space constraints and load exerted on all infrastructure components.  Netflow, while not a substitute for PCAP, is a high-level snapshot summary of network flows that would be contained in the PCAP files.  If one does not wish to ingest PCAP then at least enabling Netflow is recommended.  Metron uses YAF to generate IPFIX (Netflow) data from Metron's PCAP probe.  So the output of the probe is IPFIX instead of raw packets.  If Netflow is generated instead of PCAP then the netflow data goes to the generic Parsing topology instead of the PCAP topology. 

#### Snort Capture Designe

![1529762992392](C:\Users\Jelena\AppData\Local\Temp\1529762992392.png)

Snort is one of the more popular Network Intrusion Prevention Systems (NIPS) out there today.  Snort monitors network traffic and produces alerts that are generated based on signatures from [community rules](https://www.snort.org/faq/what-are-community-rules).  Metron plays the output of the [packet capture probe](https://cwiki.apache.org/confluence/display/METRON/Metron+Packet+Capture+Probe+Design) to Snort and whenever Snort alerts are triggered Metron uses Apache Flume to pipe these alerts to a Kafka topic.  Once Snort alerts land into Kafka topic they are then picked up by the parsing topology. 

## Domain Specific Languages

In Metron, we have two domain specific languages which are used for filtering and simple data transformation: 

- Stellar Query Language
- Stellar Tranformation Lenguage

### Stellar Query Language

The query language supports the following:

-  Referencing fields in the enriched JSON

- Simple boolean operations: and, not, or
- Simple comparison operations <, >, <=, >=
- Determining whether a field exists (via exists)
- The ability to have parenthesis to make order of operations explicit
- A fixed set of functions which take strings and return boolean. Currently:
  - IN_SUBNET (ip, cidr1, cidr2, ...)
  - IS_EMPTY (str)
  - STARTS_WITH(str, prefix)
  - ENDS_WITH(str, suffix)
  - REGEXP_MATCH(str, pattern)
  - IS_IP : Validates that the input fields are an IP address. By default, if no second arg is set, it assumes IPV4, but you can specify the type by passing in either IPV6 or IPV4 to the second argument.
  - IS_DOMAIN
  - IS_EMAIL
  - IS_URL
  - IS_DATE
  - IS_INTEGER
  - A fixed set of transformation functions:
  - TO_LOWER(string) : Transforms the first argument to a lowercase string
  - TO_UPPER(string) : Transforms the first argument to an uppercase string
  - TO_STRING(string) : Transforms the first argument to a string
  - TO_INTEGER(x) : Transforms the first argument to an integer
  - TO_DOUBLE(x) : Transforms the first argument to a double
  -  TRIM(string) : Trims whitespace from both sides of a string.
  -  JOIN(list, delim) : Joins the components of the list with the specified delimiter
  - SPLIT(string, delim) : Splits the string by the delimiter. Returns a list.
  - GET_FIRST(list) : Returns the first element of the list
  - GET_LAST(list) : Returns the last element of the list
  - GET(list, i) : Returns the i'th element of the list (i is 0-based).
  - MAP_GET(key, map, default) : Returns the value associated with the key in the map. If the key does not exist, the default will be returned. If the default is unspecified, then null will be returned.
  - DOMAIN_TO_TLD(domain) : Returns the TLD of the domain.
  - DOMAIN_REMOVE_TLD(domain) : Remove the TLD of the domain.
  - DOMAIN_REMOVE_SUBDOMAINS(domain) : Remove the sub domain of the domain
  - REMOVE_TLD(domain) : Removes the TLD from the domain.
  - URL_TO_HOST(url) : Returns the host from a URL
  - URL_TO_PROTOCOL(url) : Returns the protocol from a URL
  - URL_TO_PORT(url) : Returns the port from a URL
  - URL_TO_PATH(url) : Returns the path from a URL
  - TO_EPOCH_TIMESTAMP(dateTime, format, timezone) : Returns the epoch timestamp of the dateTime given theformat. If the format does not have a timestamp and you wish to assume a given timestamp, you may specify thetimezone optionally.

### Stellar Transformation Language

For a variety of components, there is the need to transform messages and compose those transformations in a pluggable way. For this purpose, there is a simple DSL to allow functions to be defined for common transformations and to have those functions be composed.

The functions currently supported are:

- TO_LOWER(string) : Transforms the first      argument to a lowercase string

- TO_UPPER(string) : Transforms the first argument to an      uppercase string

- TO_STRING(string) : Transforms the first argument to a string

- TO_INTEGER(x) : Transforms the first argument to an integer

- TO_DOUBLE(x) : Transforms the first argument to a double

- TRIM(string) : Trims whitespace from both sides of a string.

- JOIN(list, delim) : Joins the components of the list with the specified delimiter

- SPLIT(string, delim) : Splits the string by the delimiter. Returns a list.

- GET_FIRST(list) : Returns the first element of the list

- GET_LAST(list) : Returns the last element of the list

- GET(list, i) : Returns the i'th element of the list (i is 0-based).

- MAP_GET(key, map, default) : Returns the value associated with      the key in the map. If the key does not exist, the default will be      returned. If the default is unspecified, then null will be returned.

- DOMAIN_TO_TLD(domain) : Returns the TLD of the domain.

- DOMAIN_REMOVE_TLD(domain) : Remove the TLD of the domain.

- REMOVE_TLD(domain) : Removes the TLD from the domain.

- URL_TO_HOST(url) : Returns the host from a URL

- URL_TO_PROTOCOL(url) : Returns the protocol from a URL

- URL_TO_PORT(url) : Returns the port from a URL

- URL_TO_PATH(url) : Returns the path from a URL

- TO_EPOCH_TIMESTAMP(dateTime, format, timezone) : Returns the epoch timestamp of the dateTime given the format. If the format does not have      a timestamp and you wish to assume a given timestamp, you may specify the timezoneoptionally.

  

# MODULE 4 - METRON DEPLOYMENT

## Ambari 

 Project from Apache Metron (incubating) repo (<https://github.com/apache/metron>) provides a Management Pack (MPack) extension for [Apache Ambari](https://ambari.apache.org/) that simplifies the provisioning, management and monitoring of Metron on clusters of any size (<https://github.com/apache/metron/tree/master/metron-deployment/packaging/ambari>).

 This allows you to easily install Metron using a simple, guided process. This also allows you to monitor cluster health and even secure your cluster with kerberos. The computer used to deploy Metron will need the following components installed:

- **Ambari 2.4.2+**
- **Installable Metron packages**      (either RPMs or DEBs) located in a repository on each host at /localrepo.
- **A** [Node.js](https://nodejs.org/en/download/package-manager/) **repository** installed on the host running the Management and Alarm UI.

To deploy Metron you have to go through the following steps:

***Step 1. Build the Metron MPack:***

- Execute the following command from the project’s root directory.

`mvn clean package -Pmpack -DskipTests` 

***Step 2. This results in the Mpack being produced at the following location.***

`metron-deployment/packaging/ambari/metron-mpack/target/metron_mpack-x.y.z.0.tar.gz`

***Step 3. Copy the tarball to the host where Ambari Server is installed.***

***Step 4. Ensure that Ambari Server is stopped.***

***Step 5. Install the MPack.***

`ambari-server install-mpack --mpack=metron_mpack-x.y.z.0.tar.gz --verbose e`

***Step 6. Install the Metron packages (RPMs or DEBs) in a local repository on each host where a Metron component is installed. By default, the repository is expected to exist at /localrepo.***

On hosts where only a Metron client is installed, the local repository must exist, but it does not need to contain Metron packages. For example to create an empty repository for an RPM-based system, run the following commands. 

`yum install createrepo`

`mkdir /localrepo`

`cd /localrepo`

***Step 7. Metron will now be available as an installable service within Ambari.*** 

The MPack will make all Metron services available in Ambari in the same manner as any other services in a stack. These can be installed using Ambari’s user interface using “Add Services” or during an initial cluster install.

Retrieval of the GeoIP database is the only point during installation that reaches out to the internet. For an offline installation, the URL for the GeoIP database can be manually set to a local path on the file system such as file:///home/root/geoip/GeoLite2-City.mmdb.gz.

The RPMs DO NOT reach out to the internet (because there is currently no hosting for them). They look on the local filesystem in /localrepo.

There are a few limitations that should be addressed to improve the Metron MPack installation.

- There is no      external hosting for Metron packages (either RPMs or DEBs). These have to      be built locally and installed on each host in a repository located      at /localrepo.
- Several      configuration parameters used when installing Metron could retrieved from      Ambari rather than requiring user input.
- The MPack does      not support upgrades.

## Ansible-docker

Project from Apache Metron (incubating) repo (<https://github.com/apache/metron>)

provides a a Docker Container containing all of the prerequisites required to build Metron. (<https://github.com/apache/metron/tree/master/metron-deployment/packaging/docker/ansible-docker>).

 This allows you to easily build Metron without installing all of the build dependencies manually.

As for the prerequisites, please ensure that Docker is installed and that the daemon is running.

To deploy metron you have to go through the following steps:

***Step 1. Build the Docker container***

`cd metron-deployment/packaging/docker/ansible-docker`

`docker build -t ansible-docker:latest`

***Step 2. Launch the container.*** 

`docker run -it \`

  `-v pwd/../../../..:/root/metron \`

  `-v ~/.m2:/root/.m2 \`

  `ansible-docker:latest bash`

- This maps the Metron source code along with your local Maven repository to the container. This will prevent you from having to re-download all of these dependencies each time you build Metron.

***Step 3. Execute the following inside the Docker container to build Metron***.

`cd /root/metron`

`mvn clean package -DskipTests`

- If you wish to use this build with a vagrant instance, then after building with rpms as above, modify your usual vagrant up command to skip the build role, as so:

`vagrant --ansible-skip-tags="build" up` 

## RPM-docker

 Project from Apache Metron (incubating) repo (<https://github.com/apache/metron>) provides RPM packages that allow you to install Metron on an RPM-based operating system. (<https://github.com/apache/metron/tree/master/metron-deployment/packaging/docker/rpm-docker>).

 If you are installing Metron using Ambari, these packages are necessary prerequisites when installing on an RPM-based platform. Installing Metron using **only** these packages still leaves a considerable amount of configuration necessary to get Metron running. Installing with Ambari automates these additional steps.

As for the prerequisites, please ensure that Docker is installed and that the daemon is running. 

To deploy metron you have to go through the following steps:

***Step 1. Execute the following command from the project’s root directory:*** 

`mvn clean package -DskipTests -Pbuild-rpms`

***Step 2. The packages will be accessible from the following location once the build***  

`metron-deployment/packaging/docker/rpm-docker/RPMS/noarch` 

If Metron has already been built, just the RPM packages can be built by executing the following commands. 

`cd metron-deployment`

`mvn clean package -Pbuild-debs`

Now follows the explanation how does this work. Using the build-rpms profile as shown above, effectively automates the following steps.

***Step 1. Copy the tarball for each Metron sub-project to the target working directory.*** 

***Step 2. Build a Docker image called rpm-docker that contains all of the tools needed to build the packages.***

`docker build -t rpm-docker`  

***Step 3. Execute the build.sh script within the Docker container. The argument passed to the build script is the current version of Metron.*** 

`docker run -v pwd:/root rpm-docker:latest /bin/bash -c ./build.sh <metron-version>` 

***Step 4. This results in the RPMs being generated within the following directory.*** 

`metron-deployment/packaging/docker/rpm-docker/RPMS/noarch` 

## Packer - build

Packer-build is based on the fantastic Bento project, developed by Chief: (<https://github.com/chef/bento>).

Images which are provided:

- base-centos-6.7:      Centos 6.7 + HDP. Used in the full-dev-platform Vagrant image.

As for the prerequisites, please ensure that the following is installed:

- [Packer](https://www.packer.io/) 0.12.2
- [Virtualbox](https://www.virtualbox.org/) 5.0.16+      (Tested with 5.0.20)

To build both images navigate to <your-project-directory>/metron-deployment/packer-build and execute next command.

`bin/bento build` 

 Packer will build both images and export .box files to the ./builds directory. 

To build single images, navigate to *your-project-directory*/metron-deployment/packer-build and execute next command (for base Centos full-dev): 

`bin/bento build base-centos-6.7.json` 

For using your new box file, modify the relevant Vagrantfile (full-dev-platform) replacing the lines: 

`<pre><code>config.vm.box = "<i>box_name</i>"`

`config.ssh.insert_key = true</code></pre>`

width:

`<pre></code>config.vm.box = "<i>test_box_name</i>"`

`config.vm.box = "<i>PathToBoxfile/Boxfilename</i>"`

`config.ssh.insert_key = true</code></pre>`

Launch the image as usual.

- Note: Vagrant will cache boxes, you can force Vagrant to reload your box by      running next command before launching your new image.

`vagrant box remove *test_box_name*` 

